{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "14hxZe85SZg1kGx1IRQSsx3MfoJ5LleI3",
      "authorship_tag": "ABX9TyPtQsShGSZ2TkJWjStK6gtI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS3QH-z9VufW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8051564b-e479-48d3-c152-970f12017061"
      },
      "source": [
        "import torch\n",
        "import functools\n",
        "import numpy  as np\n",
        "from IPython.core.debugger import set_trace\n",
        "import torchvision\n",
        "from tqdm import trange\n",
        "\n",
        "%pylab inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkpZYQpkGaDa"
      },
      "source": [
        "https://pytorch.org/tutorials/beginner/pytorch_with_examples.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6CT3qtxODD1"
      },
      "source": [
        "Функция регистр добавляет в класс тензор метод mul, т.к.\n",
        "мул наследуется от класса Function то он имеет метод apply\n",
        "именно туда мы и перейдем\n",
        "\n",
        "        - setattr(Tensor, name, functools.partialmethod(fn.apply, fn))\n",
        "        - fn это мул <class '__main__.Mul'>\n",
        "        - name = 'mul'\n",
        "        - затем попав в метод apply (fn.apply)\n",
        "            - arg(fn) это аргумент который мы передали в apply\n",
        "\n",
        "и получается что  ctx это класс MUl, вызывает класс Tensor и передаем в него \n",
        "        \n",
        "        - Tensor(arg.forward(ctx, self.data, *[t.data for t in x]))\n",
        "        - self this a = 1\n",
        "        - arg <class '__main__.Mul'>\n",
        "        - x = 3 or b\n",
        "        - self.data => 1.data=> self this tensor after .data get array [1]\n",
        "        - 'подставим'\n",
        "        - Mul.forward (x= ( self.data, y = *[t.data for t in x]))\n",
        "            - save x, y\n",
        "            - mul x * y \n",
        "- ctx это класс мул он передается для сохранения значений x, y\n",
        "(method save tensor)\n",
        "- затем мы сохраняем ctx  в переменную _ctx  класса тензор\n",
        "- затем если мы выполним метод backward in class Tensor\n",
        "произойдет следующие\n",
        "\n",
        "        - пока не вызвали(backward) в классе Tensor есть\n",
        "        только результат мул и сохраненный класс мул\n",
        "        - и так вызываем\n",
        "\n",
        "        if self._ctx is None:\n",
        "            return\n",
        "            проходим тк не нон\n",
        "        if self.grad is None and fill:\n",
        "            # iniy first grad ones\n",
        "            assert self.data.size == 1\n",
        "            self.grad = np.ones_like(self.data)      \n",
        "        assert(self.grad is not None) \n",
        "        \n",
        "        инициализируем градиент единицами, self.grad = [1]\n",
        "\n",
        "        grads = self._ctx.backward(self._ctx, self.grad)\n",
        "        \n",
        "        grads = (array([3]), array([1]))\n",
        "        - Mul.backward\n",
        "        \n",
        "            def backward(ctx, grad_out):      \n",
        "                x, y = ctx.saved_tensors =>  [array([1]), array([3])] \n",
        "                return y * grad_out, x * grad_out\n",
        "\n",
        "        получаем сохраненные значения изначальные\n",
        "        затем умножаем на градиент он равен 1 пока что\n",
        "        и возвращаем полученные значения\n",
        "        ctx.parents  это тензоры а и б\n",
        "            \n",
        "            if len(self._ctx.parents) == 1:\n",
        "                grads = [grads]\n",
        "\n",
        "        это сделано чтоб использовать зип\n",
        "            \n",
        "            - self._ctx.parents (tensor([1]), tensor([3])),\n",
        "            - grads = (array([3]), array([1]))\n",
        "\n",
        "            for t, g in zip(self._ctx.parents, grads):\n",
        "                # t  Tensor\n",
        "                if g.shape != t.data.shape:\n",
        "                    print('grad shape must match tensor shape')\n",
        "                    assert(False)           \n",
        "                t.grad = g"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-L0Wj5YWCNG"
      },
      "source": [
        "# make base class\n",
        "class Tensor:\n",
        "    def __init__(self, data):\n",
        "\n",
        "        if type(data) != np.ndarray:\n",
        "            set_trace()\n",
        "            print('error type data %r' % data)\n",
        "            assert(False)\n",
        "        self.data = data        \n",
        "        self.grad = None\n",
        "        self._ctx = None\n",
        "    \n",
        "    def __repr__(self):\n",
        "        # tensor([1.]))\n",
        "        return f'tensor({self.data})'\n",
        "\n",
        "    def backward(self, fill = True):\n",
        "        \n",
        "        # print(\"running backward on\", self)\n",
        "\n",
        "        if self._ctx is None:\n",
        "            return\n",
        "\n",
        "        if self.grad is None and fill:\n",
        "            # iniy first grad ones\n",
        "            assert self.data.size == 1\n",
        "            self.grad = np.ones_like(self.data)\n",
        "        \n",
        "        assert(self.grad is not None)  \n",
        "\n",
        "        \"\"\"\n",
        "        _ctx.backward return from <class '__main__.Mul'> \n",
        "        and method Mul.backward return y * grad_out, x * grad_out\n",
        "        \n",
        "        \"\"\"      \n",
        "        grads = self._ctx.backward(self._ctx, self.grad)\n",
        "        # print('Func name: ',type(self._ctx))\n",
        "        # print('Grad: ', self.grad.shape)\n",
        "        # print('Self: ', self.data.shape)\n",
        "        # set_trace()\n",
        "        if len(self._ctx.parents) == 1:\n",
        "            grads = [grads]\n",
        "\n",
        "        # print(self._ctx.parents, grads)\n",
        "\n",
        "        for t, g in zip(self._ctx.parents, grads):\n",
        "            # t  Tensor\n",
        "            \"\"\"\n",
        "            print(g.shape,t.data.shape)\n",
        "\n",
        "                    (1,) (1,)\n",
        "                    (30, 10) (30, 10)\n",
        "                    (30, 10) (30, 10)\n",
        "                    (1, 30, 10) (30, 10)\n",
        "                    (30, 128) (30, 128)\n",
        "                    (30, 128) (30, 128)\n",
        "                    (30, 784) (30, 784)\n",
        "                    (784, 128) (784, 128)\n",
        "                    (128, 10) (128, 10)\n",
        "                    (30, 10) (30, 10)\n",
        "                    (1,) (1,)             \n",
        "            \"\"\"     \n",
        "            # print(g.shape, t.data.shape)\n",
        "            if g.shape != t.data.shape :\n",
        "                g = np.squeeze(g)\n",
        "              \n",
        "            \n",
        "            if g.shape != t.data.shape:\n",
        "                print('grad shape must match tensor shape')                \n",
        "                assert(False)\n",
        "            t.grad = g           \n",
        "            t.backward(False)          \n",
        "      \n",
        "         \n",
        "\n",
        "\"\"\"\n",
        "https://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
        "https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html#:~:text=beginner%2Fexamples_autograd%2Ftwo_layer_net_custom_function-,PyTorch%3A%20Defining%20New%20autograd%20Functions,PyTorch%20autograd%20to%20compute%20gradients.\n",
        "В прямом проходе мы получаем тензор, содержащий ввод и возврат\n",
        "Тензор, содержащий вывод. \n",
        "\n",
        "ctx - это объект контекста, который можно использовать\n",
        "хранить информацию для обратных вычислений. Вы можете кешировать произвольные\n",
        "объекты для использования в обратном проходе с помощью метода ctx.save_for_backward.\n",
        "\n",
        "\n",
        "При обратном проходе мы получаем тензор, содержащий градиент потери\n",
        "относительно выхода, и нам нужно вычислить градиент потерь относительно входа.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class Function:\n",
        "\n",
        "    def __init__(self, *tensor):\n",
        "        self.parents = tensor  \n",
        "        self.saved_tensors = []\n",
        "    \n",
        "    def save_for_backward(self, *x):\n",
        "        self.saved_tensors.extend(x)    \n",
        "\n",
        "    def apply(self, arg, *x):\n",
        "        \"\"\"\n",
        "        почему мы здесь а потому что fn.apply и передаем аргумент fn\n",
        "        a = Tensor(np.array([1]))\n",
        "        b = Tensor(np.array([3]))\n",
        "        \n",
        "        a.mul(b)\n",
        "        \n",
        "        arg: <class '__main__.Mul'> , fn\n",
        "        self.data -> Tensor.data->[1] a\n",
        "        [3] = b        \n",
        "        \n",
        "        \"\"\"        \n",
        "        ctx = arg(self, *x)         \n",
        "        ret = Tensor(arg.forward(ctx, self.data, *[t.data for t in x]))\n",
        "        ret._ctx = ctx\n",
        "        return ret\n",
        "\n",
        "\n",
        "def register(name, fn):\n",
        "    \"\"\"\n",
        "    class A:\n",
        "        print('hell')\n",
        "    a = A()\n",
        "    setattr(a, 'oo', lambda x: x *2)\n",
        "    a.oo(2)\n",
        "    >4\n",
        "\n",
        "    we add mul to class Tensor    \n",
        "\n",
        "    partialmethod(fumc, arg)\n",
        "    \"\"\"    \n",
        "    # set_trace()\n",
        "    setattr(Tensor, name, functools.partialmethod(fn.apply, fn))\n",
        "\n",
        "\n",
        "class Mul(Function):\n",
        "    \"\"\"\n",
        "    out = x.mul.y\n",
        "    back\n",
        "    out/dx, out/dy\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, y):\n",
        "        ctx.save_for_backward(x, y)\n",
        "        return x * y\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_out):       \n",
        "        # set_trace()\n",
        "        x, y = ctx.saved_tensors       \n",
        "        return y * grad_out, x * grad_out\n",
        "\n",
        "register('mul', Mul)\n",
        "\n",
        "class Add(Function):\n",
        "    \"\"\"sum\"\"\"\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, y):\n",
        "        ctx.save_for_backward(x, y)\n",
        "        return x + y\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_out):     \n",
        "        x, y = ctx.saved_tensors       \n",
        "        return grad_out, grad_out\n",
        "\n",
        "\n",
        "class ReLU(Function):\n",
        "    \"\"\"relu\"\"\"\n",
        "    @staticmethod\n",
        "    def forward(ctx, in_val):\n",
        "        ctx.save_for_backward(in_val)\n",
        "        return np.maximum(in_val, 0)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_out):     \n",
        "        in_val = ctx.saved_tensors         \n",
        "        grad_out[in_val[0] < 0] = 0   \n",
        "        return grad_out\n",
        "\n",
        "register('relu', ReLU)        \n",
        "\n",
        "class Sum(Function):\n",
        "    \"\"\"sum array each dx is 1\"\"\"\n",
        "    @staticmethod\n",
        "    def forward(ctx, in_val):\n",
        "       \n",
        "        ctx.save_for_backward(in_val)\n",
        "        return np.array([in_val.sum()])\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_out):\n",
        "        # set_trace()     \n",
        "        in_val = ctx.saved_tensors #!!!!!!!!!!!!!!!!!!!!!!!!!!            \n",
        "        return grad_out * np.ones_like(in_val[0])\n",
        "\n",
        "\n",
        "register('sum', Sum)\n",
        "\n",
        "class Dot(Function):\n",
        "    \"\"\"\n",
        "    a = [[1, 0], [0, 1]]\n",
        "    b = [[4, 1], [2, 2]]\n",
        "    np.dot(a, b)\n",
        "    >> array([[4, 1],\n",
        "             [2, 2]])  \n",
        "    \n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def forward(ctx, in_val, w):\n",
        "        ctx.save_for_backward(in_val, w)\n",
        "        return in_val.dot(w)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_out):     \n",
        "        in_val, w = ctx.saved_tensors\n",
        "        # set_trace()\n",
        "        # grad_out = np.squeeze(grad_out)\n",
        "        g_grad = grad_out.dot(w.T) # (10,10,1) and (128,10)  after 10, 128\n",
        "        w_grad = grad_out.T.dot(in_val).T\n",
        "        return g_grad, w_grad\n",
        "\n",
        "register('dot', Dot)\n",
        "\n",
        "\n",
        "class Log_softmax(Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, x):\n",
        "        ctx.save_for_backward(x)\n",
        "        mx = x.max(axis=1)\n",
        "        stbl = mx + np.log(np.exp(x- mx.reshape((-1, 1))).sum(axis=1))        \n",
        "        return x - stbl.reshape(-1,1)        \n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_out):     \n",
        "        x = ctx.saved_tensors\n",
        "        # set_trace() \n",
        "        return  grad_out - np.exp(x)*grad_out.sum(axis=1).reshape((-1, 1))      \n",
        " \n",
        "register('log_softmax', Log_softmax)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3mhhvLwrHLm",
        "outputId": "10ef96b3-dc19-439a-c700-e96a2ea31f9b"
      },
      "source": [
        "a = Tensor(np.array([1]))\n",
        "b = Tensor(np.array([3]))\n",
        "c = a.mul(b)\n",
        "# check how works\n",
        "print('No grad: ', a.grad, b.grad)\n",
        "c.backward()\n",
        "print('Numpy grad: ', c)\n",
        "print('Numpy Grad: ', a.grad, b.grad)\n",
        "print('-----------------')\n",
        "print('Time to torch')\n",
        "a  = torch.tensor([1.], requires_grad=True)\n",
        "b  = torch.tensor([3.], requires_grad=True)\n",
        "c = a.matmul(b)\n",
        "c.backward()\n",
        "print('Torch grad: ', c)\n",
        "print('Torch Grad: ', a.grad, b.grad)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No grad:  None None\n",
            "Numpy grad:  tensor([3])\n",
            "Numpy Grad:  [3] [1]\n",
            "-----------------\n",
            "Time to torch\n",
            "Torch grad:  tensor(3., grad_fn=<DotBackward>)\n",
            "Torch Grad:  tensor([3.]) tensor([1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkCqVatusxHW"
      },
      "source": [
        "## Test NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug9kmXcSv3mh"
      },
      "source": [
        "import requests, gzip, os, hashlib"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6C8_VxEEEXA_",
        "outputId": "77fd2197-e99c-435e-a6a3-91005b3ec2c4"
      },
      "source": [
        "\"\"\"\n",
        "why, because torchvision.datasets.MNIST(root= './', download=True) not work\n",
        "HTTPError: HTTP Error 403: Forbidden\n",
        "\"\"\"\n",
        "def load_data(url : str) -> np.array:\n",
        "    \"\"\"\n",
        "    https://www.geeksforgeeks.org/md5-hash-python/\n",
        "    https://pytorch.org/tutorials/beginner/nn_tutorial.html\n",
        "    idea not use name, hash?    \n",
        "    \n",
        "    \"\"\"    \n",
        "    tmp = os.path.join('/content/', hashlib.md5(url.encode('utf-8')).hexdigest())    \n",
        "    if os.path.isfile(tmp):\n",
        "        with open(tmp, 'rb') as f:\n",
        "            d = f.read()\n",
        "    else:\n",
        "        with open(tmp, 'wb') as f:\n",
        "            d = requests.get(url).content\n",
        "            f.write(d)\n",
        "    return np.frombuffer(gzip.decompress(d), dtype = np.uint8)\n",
        "\n",
        "x = load_data(\"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\")[16:].reshape((-1, 28, 28))\n",
        "y = load_data(\"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\")[8:]\n",
        "\n",
        "x_test = load_data(\"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\")[16:].reshape((-1, 28, 28))\n",
        "y_test = load_data(\"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\")[8:]\n",
        "\n",
        "x.shape, y.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ9tbxXGszCT"
      },
      "source": [
        "# make nn\n",
        "class NN:\n",
        "    def __init__(self, l1, l2):\n",
        "        self.l1 = Tensor(l1)\n",
        "        self.l2 = Tensor(l2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = x.dot(self.l1)\n",
        "        # x = x.relu()\n",
        "        # x = x.dot(self.l2)\n",
        "        # return x.log_softmax()\n",
        "\n",
        "        return x.dot(self.l1).relu().dot(self.l2).log_softmax()\n",
        "\n",
        "# init weight\n",
        "def weight_init(w: int, h: int , mode = 'gauss') -> np.array:\n",
        "    \"\"\"\n",
        "    w : columns, Width.\n",
        "    h : rows, Height.\n",
        "    mode : ['gaussian', 'uniform'] \n",
        "    https://discuss.pytorch.org/t/how-are-layer-weights-and-biases-initialized-by-default/13073   \n",
        "    \"\"\"\n",
        "    if mode == 'gauss':\n",
        "        w = np.random.randn(w, h) / np.sqrt(w*h)\n",
        "    else:\n",
        "        w = np.random.uniform(-1, 1, size = (w, h)) / np.sqrt(w*h)\n",
        "    return w.astype(np.float32)\n",
        "\n",
        "\n",
        "np.random.seed(13)\n",
        "lr = 0.001\n",
        "batch = 30\n",
        "l1 = weight_init(784, 128, mode = 'uniform')\n",
        "l2 = weight_init(128, 10, mode = 'uniform')\n",
        "\n",
        "model = NN(l1, l2)\n",
        "\n",
        "\n",
        "bar = trange(500)\n",
        "accuracies, losses = [], []\n",
        "for i in bar:\n",
        "    samp = np.random.randint(0, x.shape[0], size=(batch))\n",
        "    X = Tensor(x[samp].reshape((-1, 28*28)))\n",
        "    Y = y[samp]\n",
        "    z = np.zeros((len(samp), 10))\n",
        "    z[range(z.shape[0]), Y] = 1\n",
        "    z = Tensor(z)\n",
        "\n",
        "    y_ = model.forward(X)\n",
        "    # mean\n",
        "    # x_loss = (-out * x_lsm).mean(axis=1)\n",
        "    p1 = y_.mul(z)\n",
        "    loss = p1.sum().mul(Tensor(np.array([-1/y_.data.size]))) # add minus\n",
        "    # set_trace()\n",
        "    loss.backward()\n",
        "\n",
        "    cat = np.argmax(y_.data, axis=1)\n",
        "    acc = (cat == Y).mean()\n",
        "    # SGD\n",
        "    model.l1.data = model.l1.data - lr*model.l1.grad\n",
        "    model.l2.data = model.l2.data - lr*model.l2.grad\n",
        "    # printing\n",
        "    loss = loss.data\n",
        "    losses.append(loss)\n",
        "    accuracies.append(acc)\n",
        "    bar.set_description('Loss:  %.3f, Accuracy: %.3f' % (loss, acc)) \n",
        "figsize(5, 5)\n",
        "plot(losses)\n",
        "plot(accuracies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "EgV8RrhTc-ud",
        "outputId": "a0582dec-f99a-45d7-e9a7-86b02533239a"
      },
      "source": [
        "def vis_same_error(y_test_t, pred)-> None:\n",
        "\n",
        "    idx = np.argwhere(y_test_t.data != pred)\n",
        "    bad = x_test[idx]  \n",
        "    tmp = []\n",
        "    for _ in range(12):\n",
        "        tmp.append(np.random.randint(bad.shape[0]))\n",
        "    \n",
        "    figsize(10, 10)\n",
        "    imshow(np.concatenate(bad[tmp].reshape(4, 28*3, 28), axis = 1))\n",
        "    print('')\n",
        "    print('Predicted: ', pred[idx][tmp].ravel(), 'Target', y_test_t.data[idx][tmp].ravel())\n",
        "\n",
        "\n",
        "def evaluate(model, x, y)-> None:\n",
        "    y_= model.forward(x)\n",
        "    # print(y_.data.shape)\n",
        "    pred =  np.argmax(y_.data, axis =1)\n",
        "    acc = (y.data == pred).mean()\n",
        "    print('Accuracy model: ', acc)\n",
        "    print('Bad count: ', int(y.data.shape[0] * (1 - acc)))\n",
        "    vis_same_error(y_test_t, pred)\n",
        "\n",
        "\n",
        "x_test_t = Tensor(x_test.reshape(-1, 28*28))\n",
        "y_test_t = Tensor(y_test)\n",
        "evaluate(model, x_test_t, y_test_t)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy model:  0.9148\n",
            "Bad count:  852\n",
            "\n",
            "Predicted:  [6 7 2 6 9 4 5 3 9 2 4 1] Target [5 8 3 5 4 7 8 8 3 9 9 7]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVdPs9NG97tG"
      },
      "source": [
        "TODO\n",
        "\n",
        "- make cov\n",
        "- make adam\n",
        "-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwiQfcB03IRb"
      },
      "source": [
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N_8jTP6EdCm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly4yrHUlEdAe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyrAPwWCEc-f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUJIz7K6Ec8H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7uIZgFCEc4O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}